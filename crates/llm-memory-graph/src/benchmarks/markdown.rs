//! Markdown report generation for benchmark results
//!
//! This module provides functionality to generate human-readable markdown
//! reports from benchmark results, following the canonical format.

use super::result::BenchmarkResult;
use anyhow::{Context, Result};
use std::fs;
use std::path::{Path, PathBuf};

/// Default summary markdown file name
pub const SUMMARY_FILE: &str = "summary.md";

/// Generate a markdown summary report from benchmark results
pub fn generate_summary(results: &[BenchmarkResult]) -> String {
    let mut md = String::new();

    // Header
    md.push_str("# Benchmark Results Summary\n\n");

    if let Some(first) = results.first() {
        md.push_str(&format!(
            "**Generated:** {}\n\n",
            first.timestamp.format("%Y-%m-%d %H:%M:%S UTC")
        ));
    }

    md.push_str(&format!("**Total Benchmarks:** {}\n\n", results.len()));

    // Overview table
    md.push_str("## Overview\n\n");
    md.push_str("| Benchmark Target | Mean (ns) | Std Dev (ns) | Median (ns) | Throughput (ops/s) |\n");
    md.push_str("|-----------------|-----------|--------------|-------------|--------------------|\n");

    for result in results {
        md.push_str(&format!(
            "| {} | {} | {} | {} | {} |\n",
            result.target_id,
            format_opt_f64(result.mean_ns()),
            format_opt_f64(result.std_dev_ns()),
            format_opt_f64(result.median_ns()),
            format_opt_f64(result.throughput())
        ));
    }

    md.push_str("\n");

    // Detailed results
    md.push_str("## Detailed Results\n\n");

    for result in results {
        md.push_str(&format!("### {}\n\n", result.target_id));
        md.push_str(&format!("**Timestamp:** {}\n\n", result.timestamp.to_rfc3339()));

        // Metrics
        md.push_str("**Metrics:**\n\n");
        md.push_str("```json\n");
        md.push_str(&serde_json::to_string_pretty(&result.metrics).unwrap_or_default());
        md.push_str("\n```\n\n");
    }

    // Footer
    md.push_str("---\n\n");
    md.push_str("*Generated by llm-memory-graph benchmark suite*\n");

    md
}

/// Write a summary markdown report to the output directory
pub fn write_summary(
    results: &[BenchmarkResult],
    output_dir: impl AsRef<Path>,
) -> Result<PathBuf> {
    let path = output_dir.as_ref().join(SUMMARY_FILE);
    let summary = generate_summary(results);

    fs::write(&path, summary)
        .with_context(|| format!("Failed to write summary to {}", path.display()))?;

    Ok(path)
}

/// Helper function to format optional f64 values
fn format_opt_f64(opt: Option<f64>) -> String {
    match opt {
        Some(val) => format!("{:.2}", val),
        None => "-".to_string(),
    }
}

/// Generate a comparison report between two sets of benchmark results
pub fn generate_comparison(
    baseline: &[BenchmarkResult],
    current: &[BenchmarkResult],
) -> String {
    use std::collections::HashMap;

    let mut md = String::new();

    md.push_str("# Benchmark Comparison Report\n\n");

    // Build lookup maps
    let baseline_map: HashMap<_, _> = baseline
        .iter()
        .map(|r| (r.target_id.clone(), r))
        .collect();

    let current_map: HashMap<_, _> = current
        .iter()
        .map(|r| (r.target_id.clone(), r))
        .collect();

    // Comparison table
    md.push_str("## Performance Changes\n\n");
    md.push_str("| Benchmark | Baseline Mean (ns) | Current Mean (ns) | Change | % Change |\n");
    md.push_str("|-----------|-------------------|------------------|--------|----------|\n");

    for (target_id, current_result) in &current_map {
        if let Some(baseline_result) = baseline_map.get(target_id) {
            let baseline_mean = baseline_result.mean_ns().unwrap_or(0.0);
            let current_mean = current_result.mean_ns().unwrap_or(0.0);

            if baseline_mean > 0.0 {
                let diff = current_mean - baseline_mean;
                let pct_change = (diff / baseline_mean) * 100.0;
                let symbol = if diff > 0.0 { "⬆" } else { "⬇" };

                md.push_str(&format!(
                    "| {} | {:.2} | {:.2} | {} {:.2} | {}{:.1}% |\n",
                    target_id,
                    baseline_mean,
                    current_mean,
                    symbol,
                    diff.abs(),
                    if diff > 0.0 { "+" } else { "" },
                    pct_change
                ));
            }
        }
    }

    md.push_str("\n");
    md.push_str("*⬆ = slower (worse), ⬇ = faster (better)*\n");

    md
}

#[cfg(test)]
mod tests {
    use super::*;
    use serde_json::json;
    use tempfile::tempdir;

    #[test]
    fn test_generate_summary() {
        let results = vec![
            BenchmarkResult::new("test1", json!({"mean_ns": 1000.0, "std_dev_ns": 100.0})),
            BenchmarkResult::new("test2", json!({"mean_ns": 2000.0, "throughput": 500000.0})),
        ];

        let summary = generate_summary(&results);

        assert!(summary.contains("# Benchmark Results Summary"));
        assert!(summary.contains("test1"));
        assert!(summary.contains("test2"));
        assert!(summary.contains("1000.00"));
        assert!(summary.contains("2000.00"));
    }

    #[test]
    fn test_write_summary() {
        let temp = tempdir().unwrap();
        let results = vec![
            BenchmarkResult::new("test", json!({"mean_ns": 1000.0})),
        ];

        let path = write_summary(&results, temp.path()).unwrap();
        assert!(path.exists());

        let content = fs::read_to_string(&path).unwrap();
        assert!(content.contains("# Benchmark Results Summary"));
    }

    #[test]
    fn test_generate_comparison() {
        let baseline = vec![
            BenchmarkResult::new("test1", json!({"mean_ns": 1000.0})),
        ];

        let current = vec![
            BenchmarkResult::new("test1", json!({"mean_ns": 800.0})),
        ];

        let comparison = generate_comparison(&baseline, &current);

        assert!(comparison.contains("# Benchmark Comparison Report"));
        assert!(comparison.contains("test1"));
        assert!(comparison.contains("1000.00"));
        assert!(comparison.contains("800.00"));
    }
}
